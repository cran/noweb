\documentclass{article}
%\usepackage{times}

\addtolength{\textwidth}{1in}
\addtolength{\oddsidemargin}{-.5in}
\setlength{\evensidemargin}{\oddsidemargin}
\usepackage{noweb}
\hypersetup{colorlinks=true}
\noweboptions{breakcode}

\title{A \emph{noweb} processor for R}
\author{Terry Therneau}

\begin{document}
\maketitle
\section{Introduction}
\begin{quotation}
Let us change or traditional attitude to the construction of programs.
Instead of imagining that our main task is to instruct a \emph{computer}
what to do, let us concentrate rather on explaining to \emph{humans}
what we want the computer to do.  (Donald E. Knuth, 1984).
\end{quotation}

The above quote is a primary rationale for \emph{literate programming}.
Knuth referred to the resulting document as a web since it contained
a mix of code fragments and associated text.  
From this single document we can \emph{weave} a pdf file for human
readers, or \emph{tangle} the file to produce code for the computer.
Daniel Mall's website on literate programming
\url{www.literateprogramming.com} has much more information.
From this beginning arose a number of implementations, e.g., CWEB for the
management of C code \url{http://www-cs-faculty.stanford.edu/~uno/cweb.html}.
Another is the \emph{noweb} system of Norman Ramsay, which is
language agnostic.  
Noweb style files for R source code, of which this document is one,
thus look just like Sweave or knitr latex files.  If we give them a
file suffix of ``.Rnw'' then they are  handled automatically by
Emacs/ESS or Rstudio.  
This provides nice formatting of the embedded R code chunks.

The .Rnw files of the resulting code are not suitable for
processing with Sweave or knitr, however; 
their goal is to insert the results of R code execution into 
a document, ours is to act as the repository and documentation for the
code itself.  These are completely different and need different tools.
Instead we use the \code{noweave} and \code{notangle} programs to
produce the latex and source code, respectively.
One problem is that the noweb package will not be found on a typical user
machine.  
Those who use unix can install noweb using the usual apt-get command, but
for Windows or MacIntosh it is not so easy.
This R package implements the noweb system entirely in R.

From a user's point of view there are two primary differences between
the creation of a knitr and noweb document.
The first is that every code chunk must have a name and the second that
code chunks do not have options.
The second of these arises from the fact that the chunks are not executed,
only echoed, and almost all of the chunk options in knitr control exectuion
or plotting details.
The requrement for a name comes about because chunks of code are arrayed
in the document for \emph{human} readability, which is almost never the
same order needed by the computer for the final code.
The labels allow the \code{notangle} program to select certain portions
of the code and to properly reorder the components that belong to it.



noweb parser in R.  
The \emph{noweb.sty} file that accompanies my version is much
simpler than the one found in the noweb source, because I use
the hyperref and fancyvrb packages for all the hard stuff.
This file itself is the source for the R noweb parser, with the
following files:
<<*>>=
<<nwread>>
<<nwparse>>
<<nwloop>>
<<nwkillamp>>
<<notangle>>
<<noweave>>
<<tab.to.blank>>
<<findverbatim>>
<<nwletter>>    
@ 
The default for the notangle funciton is to extract the code chunk named
`*'.
 
\section{Parsing}
The [[noweb]] package is based on unix pipelines.
The first step on all the pipelines is to read in a source file and
tag the sections. 
The R code reads the file into a list, each element of which is labeled
as program or text.
A noweb file consists of chunks: text chunks are signaled by a line with
@ as the first character followed by a newline or a space, and
code chunks by the [[<<identifier>>=]] string alone on a line, where
\emph{identifier} is the name of the code chunk.
The first line of the program is assumed to be a text chunk if not 
preceeded by an ampersand line.
We parse this into a simple S object, a list containing [[nwtext]] and
[[nwcode]] objects.  All tabs are turned into blanks to facilitate later
processing.

A text object that has words on the same line as the @ is treated differently
than one that does not, for breaking lines.  
Comments on the @ line don't count as a new text line,   %'
but were used by earlier versions of noweb to aid in cross-indexing.
I do not support this historical use --- such comments are tossed away.

The standalone Unix version that I have been using will try to interpret
any set of paired angle brackets on one line as the start of
a code chunk.
If one wants to have such a string left alone, e.g. as an argument to grep,
then it can be escaped by using \verb!@<<! as the start of the string.
The noweb package follows the Sweave convention that declarations
of a code chunk must start at the left margin and be alone on the line,
hence this problem never arises.
Nevertheless, to be consistent with the noweb documentation it will
strip the leading [[@]] symbol from strings of the form
[[@<<some text>>]], unless they are in a verbatim environment.

The code first finds that start of all code chunks and text chunks and
creates a matrix [[temp]] whose first row is the starting line of the
chunk, and second is the type of chunk: 1=text and 2=code.
The endline variable contains the last line of each chunk.
It then walks through one chunk at a time.
One nuisance is to avoid any apparent code start that is the
midst of a verbatim or semiverbatim environment.
(My document on how to use noweb encounters this issue.)

For a text chunk, it decides if the very first line was a blank
line.  If not, then the output is a character vector containing
all the lines.  If it is, then the blank line is suppressed
from the character vector, but a [[blankline]] attribute is
added to remind us that it once was there.  This is used to
create the Latex output in such a way that the line numbers
in the .tex file exactly match those in the .Rnw file, while
not introducing extra paragraph breaks.
Code chunks have a name extracted and
the remainder is passed through the [[nwparse]] function.
The code chunk names are used as names for the components of
the [[noweb]] object.

Finally two checks are run: make sure that any code chunk that
is referenced has been defined somewhere, and that there are
not any loops.

The nwread function creates an object of class noweb.
The final noweb object is a list with objects of class 
[[nwtext]] and [[nwcode]].  
The first of these is a character vector of the input lines,
with an optional blankline attribute.
An [[nwcode]] object has components
\begin{itemize}
  \item lines: the text of the code
  \item sourceline: the line number of the start of the text, in the
    original source file (useful when debugging)
  \item xindx, xref, indent: a set of vectors with one element for
    each included chunk that give the relative line number in this
    code where the inclusion occurs, the name of the included chunk,
    and the indentation amount for the inclusion.
\end{itemize}
Noweb code chunks are required to have a name.

The nowebSyntax object is a list that defines the text strings
that start chunks along with other options.

<<nwread>>=
nwread <- function(file, syntax) {
    if (!file.exists(file)) stop("input file not found")
    program <- tab.to.blank(readLines(file))
    if (length(program)==0) stop("input file is empty")
    vlines <- findverbatim(program, syntax)
    codestart <- grep(syntax$code, program) 
    codestart <- codestart[!(codestart %in% vlines)]
    textstart <- grep(syntax$doc, program)
    program <- nwkillat(program, vlines, syntax)  #get rid of extra @ signs

    # Normally users don't start the program with an @, so assume one
    #  Both will be NULL for a doc with no code at all, hence the "2"
    if (min(codestart, textstart, 2) > 1) textstart <- c(1, textstart)
    
    temp <- rbind( c(codestart, textstart),
                   c(rep(2, length(codestart)), rep(1, length(textstart))))
    temp <- temp[,order(temp[1,])]
    endline <- c(temp[1,-1] -1, length(program))

    output <- vector("list", ncol(temp))  #number of chunks
    oname <- rep("", ncol(temp))
    for (i in 1:ncol(temp)) {
        if (temp[2,i]==1) { # text
            blankline <- sub("^@ *","", program[temp[1,i]])
            if (blankline=="" || substring(blankline,1,1)=="%") {
                # The line is blank
                if (temp[1,i]==endline[i])
                    text <- vector("character",0)  #Nothing there!
                else text <- program[(temp[1,i]+1):endline[i]]
                attr(text, "blankline") <- TRUE
                }
            else {
                text <- blankline
                if (temp[1,i] < endline[i])
                    text <- c(text, program[(temp[1,i]+1):endline[i]])
                attr(text, "blankline") <- FALSE
                }
            class(text) <- "nwtext"
            output[[i]] <- text
            }
        
        else {  #code
            cname <-  sub(syntax$code, "\\1", program[temp[1,i]])
            if (temp[1,i] == endline[i]) code <- vector("character", 0)
            else code <- program[(temp[1,i]+1):endline[i]]
            oname[i] <- cname
            output[[i]] <- c(nwparse(code, temp[1,i], syntax))
            }
        }
    
    names(output) <- oname
    class(output) <- "noweb"
    output
    }
@ 
The [[nwparse]] routine looks for references to other code within the
lines of a code chunk.  
These are sequences of the form [[<<identifier>>]].
The resulting structure has the lines, a list of line numbers that are
pointers to other code [[xindex]], the name of the other code chunk,
and the relative indentation.
<<nwparse>>=
nwparse <- function(lines, sourceline, syntax) {
    # Look for references to other code
    indx <- grep(syntax$coderef, lines) 
    if (length(indx)) {
        xref <- sub(syntax$coderef, "\\1", lines[indx])
        indent <- sub("<<.*", "", lines[indx])
        out <- list(lines=lines, xref=xref, indent=indent, xindex=indx)
        }
    else out <- list(lines=lines, xref=NULL)
    
    out$sourceline <- sourceline #original line number in the source file
    class(out) <- "nwcode"
    out
    }
@ 
                
The code will fail when expanding a structure with a closed loop of
references.  This finds such loops.  The return value gives the shortest
loop found.
I only report one because the same loop will appear multiple times, once for
each starting point that can enter it.
<<nwloop>>=
nwloop <- function(code) {   
    xref <- lapply(code, function(x) 
                   if (inherits(x, "nwcode")) unique(x$xref) else NULL)

    nwchase <- function(chain) {
        xtemp <- xref[[chain[1]]]  #routines called by the head of the chain
        if (length(xtemp) ==0) return(NULL)
        
        for (i in 1:length(xtemp)) {
            if (!is.na(match(xtemp[i], chain))) return(c(rev(chain), xtemp[i]))
            temp <- nwchase(c(xtemp[i], chain))
            if (!is.null(temp)) return(temp)
            }
        NULL
        }
 
    cnames <- names(code)
    temp <- lapply(cnames[cnames!=""], nwchase)
    templen <- sapply(temp,length)
    if (any(templen) > 0) 
        temp[[min(which(templen==min(templen[templen>0])))]]
    else NULL
    }
@ 


The extra at sign rule:  if we see the the definition of a code
chunk prefaced by [[@]], and those
characters are not inside a \verb![[]]! or a verbatim clause,
pair, then remove the @ sign. 
This is part of the original noweb specification and I'm playing
nice with that spec: if you wanted to ensure that a pair of angle
brackets would not trigger ``I see the start of a code chunk'' then
it could be preceded by an ampersand, which would then be stripped
off in the final output.  
<<nwkillamp>>=
nwkillat <- function(program, vlines, syntax) {
    suspectlines <- grep(syntax$escapeat, program)
    suspectlines <- suspectlines[!(suspectlines %in% vlines)]

    # This is slower than Hades, but there are nearly always 0 lines in the
    #  the suspectlines set, and rarely more than 3
    for (i in suspectlines) {
        line <- strsplit(program[i], split='') #make it into a character vector
        inplay <- 1:length(line)  #index to characters not yet exempted
        while(TRUE) {
            temp <- paste(line[inplay], collapse='')
            rtemp <- regexpr(syntax$verb, temp)
            if (rtemp >0) {
                vchar <- (line[inplay])[rtemp+5]
                end <- min(0, which(line[inplay[-(1:(rtemp+5))]] == vchar))
                inplay <- inplay[-(rtemp:(rtemp+5+end))]
                }
            else if ((rtemp <- regexpr(syntax$sqexpr, temp)) >0) {
                inplay <- inplay[-(rtemp:(rtemp+attr(rtemp, 'match.length')))]
                }
            else break
            }
        # Remove the @ signs
        keep <- rep(TRUE, length(temp))
        while(1) {
            rtemp <- regexpr(syntax$escapeat, paste(line[inplay], collapse=''))
            if (rtemp>1) {
                line[inplay][rtemp] <- ' '
                keep[inplay[rtemp]] <- FALSE
                }
            else break
            }
        if (any(!keep)) program[i] <- paste(line[keep], collapse='')
    }
    program
}
@

Find any lines that are part of a verbatim environment.
An assumption here is that there is nothing important (a code chunk)
preceding but on the same line as the \verb!begin{verbatim}!,
nor anything of that type after the end of the environment.
We first have to get rid of such phrases that live inside a\verb!\verb! 
clause though, 
or this paragraph itself would trip us up.
This code does not have to be all that good, since it's only purpose
is to flag lines that the nwread routine should ignore when looking
for the start of code chunks, or nwkillat.
<<findverbatim>>=
findverbatim <- function(code, syntax){
    #Now find paired begin/end clauses
    lines <- NULL
 
    vstart <- paste("^\\\\begin\\{", syntax$verbatim, "\\}", sep='')
    vend <- paste("\\\\end\\{", syntax$verbatim, "\\}", sep='')
    for (i in 1:length(vstart)) {
        start <- grep(vstart[i], code)
        end   <- grep(vend[i], code)
        if (length(start) != length(end)) 
            stop(paste("Mismatched", syntax$verbatim[i], "pair"))
        lines <- c(lines, unlist(apply(cbind(start, end), 1, 
                                       function(x) x[1]:x[2])))
    }
    sort(unique(lines))
}
@ 

\section{Notangle}
The primary reason for wanting an R version of noweb is the notangle function, which
extracts and writes out a named R file from the noweb source.
This allows the [[coxme]] package to be built on machines that do not have
the standalone noweb package installed.
The primary work is the recursion that occurs when one code fragment
references another, and maintaining the relative indentation of the point
at which it is called.

If no target is given, the default is to extract the target named `*' %'`
if it exists, in keeping with the standalone noweb code.  If there is no
such target I extract the first code chunk.

<<notangle>>=
notangle <- function(file, target='*', out, syntax=nowebSyntax, ...) {
    if (inherits(file, "noweb")) input <- file
    else {
        if (.Platform$OS.type == "windows") 
            file <- chartr("\\", "/", file)
        input <- nwread(file, syntax)
    }

    if (missing(out)) {
        if (target=='*') {
            # Use the file name
            out <- paste(sub("\\.[^\\.]*$", "", basename(file)), "R", sep='.')
            }
        else out <- paste(target, "R", sep='.')
        }

    cname <- names(input)
    indx <- match(target, cname)
    if (is.na(indx)) {
        if (missing(target) && any(cname != '')) 
            target <- (cname[cname!=''])[1]
        else stop(paste("Code chunk", target, "not found in source file"))
        }
    
    # Verify that there are no loops
    temp <- nwloop(input)
    if (length(temp)) 
        stop(paste("Code structure has circular references: ",
                   paste(temp, collapse=" --> ")))

    program <- nwextract(input, target, prefix="")

    if (length(out)) cat(program, file=out, sep='\n')
    out
    }
@ 

Here is the actual workhorse function.
It extracts a named code chunk, recursively inserting other
named ones when they are referenced. 
If there are inclusions the data is first broken up into a 
list: element 1 is the start to the first inclusion, element 2 contains
the result of a call to nwextract on the first inclusion, element 3
from first inclusion to second inclusion, etc.  Some of the odd
elements may be empty, for instance if two inclusion lines abut.
The ifelse near the end preserves blank lines, no indentation
prefix is added to them.  It is there mostly to make output
exactly match that of the original notangle program.

Note that there can be multiple code chunks with the same name:
it is standard in noweb to display a chunk bit by bit as we
comment on its structure.  Hence the first line below can't be
[[code[target]]] as that would fetch only the first piece.
The for loop replaces each chunk with it's expansion one by one;
at the end we unlist the result.

<<notangle>>=
nwextract<- function(code, target, prefix="") {
    mycode <- code[names(code)==target]
    if (length(mycode)==0) 
        stop(paste("Program chunk '", target, "' not found", sep=""))
    
    for (chunk in 1:length(mycode)) {
        ctemp <- mycode[[chunk]]
        if (length(ctemp$xref) ==0) temp <- ctemp$lines
        else {
            inclusions <- length(ctemp$xref)
            temp <- vector("list", 2*inclusions +1)
            for (i in 1:length(ctemp$xref))
                temp[[2*i]] <- nwextract(code, ctemp$xref[i], ctemp$indent[i])
            start <- c(1, ctemp$xindex+1) #start and end of non-inclusions
            end   <- c(ctemp$xindex-1, length(ctemp$lines))
            for (i in 1:length(start)) 
                if (start[i]<=end[i]) 
                    temp[[2*i -1]] <- ctemp$lines[start[i]:end[i]]
            temp <- unlist(temp)
            }
        mycode[[chunk]] <- ifelse(temp=="", "", paste(prefix, temp, sep=''))
        }
    as.vector(unlist(mycode))   #kill any names added to the vector
    }
@ 

Convert tabs to blanks. If a tab occurs at position 1 then 8 blanks get added,
if at position 2 then 7 blanks get added, etc. If there are two tabs in a
row, then the second one is at postion 9, not 2 -- you have to do them
sequentially.  The key is to restart your count at 1 after each tab.
The blanks variable contains various size inserts.
<<tab.to.blank>>=
tab.to.blank <- function(x, tabstop=8) {
    blanks <- rep(" ", tabstop)
    for (i in (tabstop-1):1) blanks[i] <- paste(blanks[i +0:1], collapse='')

    temp <- strsplit(x, '')
    linefix <- function(x) {
        n <- length(x)
        if (n==0) ""
        else {
            since.last.tab <- 1:n - cummax(ifelse(x=='\t', 1:n, 0))
            newx <- ifelse(x=='\t', blanks[1+ since.last.tab%%tabstop], x)
            paste(newx, collapse='')
            }
        }
    unlist(lapply(temp, linefix))
    }
@ 

